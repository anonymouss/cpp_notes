# 朴素贝叶斯

1. 朴素贝叶斯法是典型的生成学习方法。生成方法由训练数据学习联合概率分布$P(X, Y)$，然后球的后验概率分布$P(Y|X)$。具体来说，利用训练数据学习$P(X|Y)$和$P(Y)$的估计得到联合概率分布：

    $P(X, Y) = P(Y)P(X|Y)$。
    
    概率估计方法可以是极大似然估计或贝叶斯估计。

2. 朴素贝叶斯方法的基本假设是条件独立性：

    $$\begin{align*}P(X=x|Y=c_k)=&P(X^{(1)}=x^{(1)},\cdots,X^{(n)}=x^{(n)}|Y=c_k)\\=&\prod_{j=1}^n{P(X_{(j)}=x_{(j)}|Y=c_k)}\end{align*}$$

    这是一个较强的假设。由于这一假设，模型包含的条件概率的数量大为减少，朴素贝叶斯法的学习与预测大为简化。因而朴素贝叶斯法高效，且易于实现。其缺点是分类的性能不一定很高。

3. 朴素贝叶斯法利用贝叶斯定理与学到的联合概率模型进行分类预测。

    $P(Y|X) = \frac{P(X,Y)}{P(X)}=\frac{P(Y)P(X|Y)}{\sum_YP(Y)P(X|Y)}$

    将输入$x$分到后验概率最大的类$y$。

    $y = \arg\max_{c_k}{P(Y=c_k)\prod_{j=1}^n{P(X_j=x^{(j)}|Y=c_k)}}$

    后验概率最大等价于0-1损失函数时的期望风险最小化。
